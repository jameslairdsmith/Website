<!DOCTYPE html>
<html lang="en-US">
<head>

<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<meta name="description" content="Eric Ekholm&#39;s personal website">
<meta name="keywords" content="minimalist,blog,goa,hugo,developer,education,data,writing">

<base href="/">

<title>
  Eric Ekholm - Scrantonicity - Part 1 
</title>

<meta name="generator" content="Hugo 0.61.0" />


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css">


<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,400|Roboto+Slab:400,700|Roboto:300,300i,400,400i,500,500i,700,700i">
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.2/css/all.css" integrity="sha384-oS3vJWv+0UjzBfQzYUhtDYW+Pj2yciDJxpsK1OYPAYjqT085Qq/1cq5FLXAZQ7Ay" crossorigin="anonymous">
<link rel="stylesheet" href="/css/main.css">
<link rel="stylesheet" href="/css/custom.css">




<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" href="/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/favicon-16x16.png" sizes="16x16">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
<meta name="theme-color" content="#ffffff">

</head>
<body lang="en-US">
<div class="container">


<header class="row text-left title">
  <h1 class="title">Scrantonicity - Part 1</h1>
</header>
<section id="category-pane" class="row meta">
  
  <div class="col-md-12">
    <h6 class="text-left meta">
        PUBLISHED ON MAR 14, 2020 
      
    </h6>
  </div>
  
</section>
<section id="content-pane" class="row">
  <div class="col-md-12 text-justify content">
    
    
    
    
<script src="/rmarkdown-libs/kePrint/kePrint.js"></script>


<div id="i-just-want-to-lie-on-the-beach-and-eat-hog-dogs" class="section level2">
<h2>I Just Want to Lie on the Beach and Eat Hog Dogs</h2>
<p>Who doesn’t love <em>The Office</em>? I went through high school and college following the on-again off-again romance of Jim and Pam, the Icarus-esque ascendancy and fall of Ryan the Temp, and the perpetual cringey-ness of Michael Scott. And aside from that handful of people who fled the room in a cold panic at even the mention of “Scott’s Tots,” I think this was probably true for most of my generation. You’d be hard pressed to go to a Halloween party in the late aughts without seeing someone dressed in the tan-and-yellow palette of Dwight Schrute, and before the modern era of Netflix and Hulu, we regularly set aside Thursday nights to tune into NBC.</p>
<p>And although I was a big <em>Office</em> fan several years ago, I haven’t thought too too much about it recently – at least until I stumbled across the release of the <code>{schrute}</code> package recently. <a href="https://CRAN.R-project.org/package=schrute"><code>{schrute}</code></a> is an R package with one purpose – presenting the entire transcripts of <em>The Office</em> in tibble format, making the dialogue of the show much easier to analyze. I played around with the package and a <a href="https://github.com/ekholme/TidyTuesday/blob/master/53%20-%20the%20office/jim%20pam%20script.Rmd">quick sentiment analysis</a> back in December when I looked at the sentiments expressed by Jim and Pam over the course of the series:</p>
<p><a href="https://github.com/ekholme/TidyTuesday/blob/master/53%20-%20the%20office/jim_pam_sentiments.jpg?raw=true"><img src="https://github.com/ekholme/TidyTuesday/blob/master/53%20-%20the%20office/jim_pam_sentiments.jpg?raw=true" /></a></p>
<p>There’s a ton more we can do with the package, though, and with the transcripts available and in a clean format, plus all of the tools <code>R</code> has available for text analysis, I figured I’d do a mini-series of blog posts analyzing some of the data. The plan (as of now) is to start this first post with some exploratory analyses and visualizations, then move into some other types of modeling in later posts. I’ll also include all of my code throughout.</p>
<p><br/></p>
<p><em><strong>As a quick aside, a lot of the text analyses I’m going to work through in this first post come from the <a href="https://www.tidytextmining.com/">Text Mining with R book by Julia Silge and David Robinson.</a> I’d strongly recommend this to anyone looking to dive into analyzing text data.</strong></em></p>
</div>
<div id="setup" class="section level2">
<h2>Setup</h2>
<p>First, let’s read in the data. I’m also going to limit the data to the first seven seasons, which spans the “Michael Scott” era. Not only because these are the best seasons (which they undoubtedly are), but also because doing so eliminates a major confounding factor (i.e. Steve Carell leaving the show) from the analysis.</p>
<pre class="r"><code>office &lt;- theoffice %&gt;%
  filter(as.numeric(season) &lt;= 7)

glimpse(office)</code></pre>
<pre><code>## Observations: 41,348
## Variables: 9
## $ index            &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,...
## $ season           &lt;chr&gt; &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;0...
## $ episode          &lt;chr&gt; &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;0...
## $ episode_name     &lt;chr&gt; &quot;Pilot&quot;, &quot;Pilot&quot;, &quot;Pilot&quot;, &quot;Pilot&quot;, &quot;Pilot&quot;, &quot;Pilo...
## $ director         &lt;chr&gt; &quot;Ken Kwapis&quot;, &quot;Ken Kwapis&quot;, &quot;Ken Kwapis&quot;, &quot;Ken Kwa...
## $ writer           &lt;chr&gt; &quot;Ricky Gervais;Stephen Merchant;Greg Daniels&quot;, &quot;Ri...
## $ character        &lt;chr&gt; &quot;Michael&quot;, &quot;Jim&quot;, &quot;Michael&quot;, &quot;Jim&quot;, &quot;Michael&quot;, &quot;Mi...
## $ text             &lt;chr&gt; &quot;All right Jim. Your quarterlies look very good. H...
## $ text_w_direction &lt;chr&gt; &quot;All right Jim. Your quarterlies look very good. H...</code></pre>
<p>Just to check that the data we have matches what we’re expecting, let’s take a look at which seasons we have, plus how many episodes we have per season.</p>
<pre class="r"><code>office %&gt;%
  distinct(season, episode) %&gt;%
  count(season, name = &quot;num_episodes&quot;)</code></pre>
<pre><code>## # A tibble: 7 x 2
##   season num_episodes
##   &lt;chr&gt;         &lt;int&gt;
## 1 01                6
## 2 02               22
## 3 03               23
## 4 04               14
## 5 05               26
## 6 06               24
## 7 07               24</code></pre>
<p>This generally matches what Wikipedia is telling me once we account for two-part episodes, and we can see that we only have the first seven seasons.</p>
<div id="me-think-why-waste-time-say-lot-word-when-few-word-do-trick" class="section level3">
<h3>Me think, why waste time say lot word, when few word do trick</h3>
<p>A few questions we can ask here involve how much/how often different characters speak. Probably the most basic question is: who has the most lines?</p>
<pre class="r"><code>top_20_chars &lt;- office %&gt;%
  count(character, sort = TRUE) %&gt;%
  top_n(20) %&gt;%
  pull(character)</code></pre>
<pre><code>## Selecting by n</code></pre>
<pre class="r"><code>office %&gt;%
  filter(is.element(character, top_20_chars)) %&gt;%
  count(character, sort = TRUE) %&gt;%
  ggplot(aes(x = fct_reorder(character, n), y = n)) +
  geom_col(fill = purple) +
  labs(
    x = &quot;&quot;,
    y = &quot;Number of Lines&quot;,
    title = &quot;Who Has the Most Lines?&quot;
  ) +
  coord_flip()</code></pre>
<p><img src="/blog/office-part1_files/figure-html/most%20lines-1.png" width="672" /></p>
<p>It’s not surprising to me that Michael has the most lines, but the magnitude of the difference between him and Dwight is a bit surprising.</p>
<p>What if we look at the number of lines per season?</p>
<pre class="r"><code>office %&gt;%
  filter(is.element(character, top_20_chars)) %&gt;%
  count(character, season, sort = TRUE) %&gt;%
  ggplot(aes(x = as.numeric(season), y = n, color = character)) +
    geom_line() +
    geom_point()</code></pre>
<p><img src="/blog/office-part1_files/figure-html/character%20lines%20lineplot-1.png" width="672" /></p>
<p>This isn’t terribly informative – let’s go back to our bar graph.</p>
<pre class="r"><code>office %&gt;%
  filter(is.element(character, top_20_chars)) %&gt;%
  count(character, season, sort = TRUE) %&gt;%
  group_by(season) %&gt;%
  top_n(n = 5) %&gt;%
  ungroup() %&gt;%
  ggplot(aes(x = fct_reorder(character, n), y = n)) +
    geom_col(fill = purple) +
    coord_flip() +
    facet_wrap(~season, scales = &quot;free&quot;) +
    labs(
      title = &quot;Number of Lines by Season&quot;,
      x = &quot;&quot;,
      y = &quot;&quot;
    ) +
    theme_minimal()</code></pre>
<pre><code>## Selecting by n</code></pre>
<p><img src="/blog/office-part1_files/figure-html/lines%20by%20season-1.png" width="672" /></p>
<p>Again, not surprising that Michael has the most lines across all seasons. Dwight, Jim, and Pam are always the next three, but the orders change a bit between seasons. The fifth spot is where we see some movement, with Oscar and Jan sneaking in before Andy joins the show in Season 3. And check out Ryan in S4!</p>
</div>
<div id="sometimes-ill-start-a-sentence-and-i-dont-even-know-where-its-going" class="section level3">
<h3>Sometimes I’ll start a sentence and I don’t even know where it’s going</h3>
<p>So, above, we just looked at the number of <em>lines</em> each character had. Another option is to do some analyses at the word level. For instance, we can look at patterns of word usage for individual characters, between characters, and over time.</p>
<p>To start with this, I’m going to restructure the data so we have one word per row in our tibble. I’m also going to remove “stop words” (e.g. “a,” “the,” “at”), since these will show up a lot but (for our purposes) aren’t actually all that meaningful:</p>
<pre class="r"><code>office_words &lt;- office %&gt;%
  unnest_tokens(word, text) %&gt;%
  anti_join(stop_words)</code></pre>
<pre><code>## Joining, by = &quot;word&quot;</code></pre>
<pre class="r"><code>glimpse(office_words)</code></pre>
<pre><code>## Observations: 125,041
## Variables: 9
## $ index            &lt;int&gt; 1, 1, 1, 2, 2, 3, 3, 3, 4, 4, 6, 6, 6, 6, 6, 6, 6,...
## $ season           &lt;chr&gt; &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;0...
## $ episode          &lt;chr&gt; &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;01&quot;, &quot;0...
## $ episode_name     &lt;chr&gt; &quot;Pilot&quot;, &quot;Pilot&quot;, &quot;Pilot&quot;, &quot;Pilot&quot;, &quot;Pilot&quot;, &quot;Pilo...
## $ director         &lt;chr&gt; &quot;Ken Kwapis&quot;, &quot;Ken Kwapis&quot;, &quot;Ken Kwapis&quot;, &quot;Ken Kwa...
## $ writer           &lt;chr&gt; &quot;Ricky Gervais;Stephen Merchant;Greg Daniels&quot;, &quot;Ri...
## $ character        &lt;chr&gt; &quot;Michael&quot;, &quot;Michael&quot;, &quot;Michael&quot;, &quot;Jim&quot;, &quot;Jim&quot;, &quot;Mi...
## $ text_w_direction &lt;chr&gt; &quot;All right Jim. Your quarterlies look very good. H...
## $ word             &lt;chr&gt; &quot;jim&quot;, &quot;quarterlies&quot;, &quot;library&quot;, &quot;told&quot;, &quot;close&quot;, ...</code></pre>
<p>We can see that we have a new column, <code>word</code>, with one word per row. We can also see that the only words in the first line of dialogue (All right Jim. Your quarterlies look very good. How are things at the library?) that make it through the stop words filter are <code>jim</code>, <code>quarterlies</code>, and <code>library</code>. We could fiddle with the stop words list if we wanted to keep words like “good” or “things,” but I’m not too concerned about that for now.</p>
<p>As a first pass, let’s take a look at our 20 characters with the most lines of dialogue and see what each character’s most commonly-used word is:</p>
<pre class="r"><code>office_words %&gt;%
  filter(is.element(character, top_20_chars)) %&gt;%
  count(character, word, sort = TRUE) %&gt;%
  group_by(character) %&gt;%
  top_n(n = 1) %&gt;%
  kable(format = &quot;html&quot;) %&gt;%
  kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;condensed&quot;, &quot;hover&quot;))</code></pre>
<pre><code>## Selecting by n</code></pre>
<table class="table table-striped table-condensed table-hover" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
character
</th>
<th style="text-align:left;">
word
</th>
<th style="text-align:right;">
n
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Michael
</td>
<td style="text-align:left;">
yeah
</td>
<td style="text-align:right;">
563
</td>
</tr>
<tr>
<td style="text-align:left;">
Dwight
</td>
<td style="text-align:left;">
michael
</td>
<td style="text-align:right;">
280
</td>
</tr>
<tr>
<td style="text-align:left;">
Jim
</td>
<td style="text-align:left;">
yeah
</td>
<td style="text-align:right;">
274
</td>
</tr>
<tr>
<td style="text-align:left;">
Pam
</td>
<td style="text-align:left;">
michael
</td>
<td style="text-align:right;">
257
</td>
</tr>
<tr>
<td style="text-align:left;">
Jan
</td>
<td style="text-align:left;">
michael
</td>
<td style="text-align:right;">
159
</td>
</tr>
<tr>
<td style="text-align:left;">
Andy
</td>
<td style="text-align:left;">
yeah
</td>
<td style="text-align:right;">
138
</td>
</tr>
<tr>
<td style="text-align:left;">
Kevin
</td>
<td style="text-align:left;">
yeah
</td>
<td style="text-align:right;">
79
</td>
</tr>
<tr>
<td style="text-align:left;">
David
</td>
<td style="text-align:left;">
michael
</td>
<td style="text-align:right;">
67
</td>
</tr>
<tr>
<td style="text-align:left;">
Ryan
</td>
<td style="text-align:left;">
yeah
</td>
<td style="text-align:right;">
66
</td>
</tr>
<tr>
<td style="text-align:left;">
Oscar
</td>
<td style="text-align:left;">
michael
</td>
<td style="text-align:right;">
65
</td>
</tr>
<tr>
<td style="text-align:left;">
Phyllis
</td>
<td style="text-align:left;">
michael
</td>
<td style="text-align:right;">
59
</td>
</tr>
<tr>
<td style="text-align:left;">
Toby
</td>
<td style="text-align:left;">
michael
</td>
<td style="text-align:right;">
50
</td>
</tr>
<tr>
<td style="text-align:left;">
Darryl
</td>
<td style="text-align:left;">
na
</td>
<td style="text-align:right;">
48
</td>
</tr>
<tr>
<td style="text-align:left;">
Kelly
</td>
<td style="text-align:left;">
god
</td>
<td style="text-align:right;">
44
</td>
</tr>
<tr>
<td style="text-align:left;">
Angela
</td>
<td style="text-align:left;">
dwight
</td>
<td style="text-align:right;">
40
</td>
</tr>
<tr>
<td style="text-align:left;">
Holly
</td>
<td style="text-align:left;">
yeah
</td>
<td style="text-align:right;">
39
</td>
</tr>
<tr>
<td style="text-align:left;">
Erin
</td>
<td style="text-align:left;">
michael
</td>
<td style="text-align:right;">
37
</td>
</tr>
<tr>
<td style="text-align:left;">
Karen
</td>
<td style="text-align:left;">
yeah
</td>
<td style="text-align:right;">
28
</td>
</tr>
<tr>
<td style="text-align:left;">
Stanley
</td>
<td style="text-align:left;">
michael
</td>
<td style="text-align:right;">
27
</td>
</tr>
<tr>
<td style="text-align:left;">
Meredith
</td>
<td style="text-align:left;">
wait
</td>
<td style="text-align:right;">
22
</td>
</tr>
</tbody>
</table>
<p>So, that’s not great. We can see that our stop words didn’t pick up “yeah.” One way around this would be to filter out additional words like “yeah,” “hey,” etc. that aren’t in our stop words list. But we’ll probably still leave out some common words that we might not want to show up in our exploration. A better approach is probably to use the tf-idf statistics (term frequency-inverse document frequency), which adjusts the weight a term is given in the analysis for each character by how commonly the word is used by all characters, with more common words getting lower weights. Essentially, this lets us figure out which words are important/unique to each of our characters.</p>
<pre class="r"><code>office_words %&gt;%
  filter(is.element(character, top_20_chars)) %&gt;%
  count(character, word, sort = TRUE) %&gt;%
  bind_tf_idf(word, character, n) %&gt;%
  group_by(character) %&gt;%
  top_n(n = 5, wt = tf_idf) %&gt;%
  slice(1:5) %&gt;%
  ungroup() %&gt;%
  ggplot() +
    geom_col(aes(x = reorder_within(word, tf_idf, within = character), y = tf_idf), fill = purple) +
    facet_wrap(~character, scales = &quot;free&quot;) +
    coord_flip() +
    scale_x_reordered() +
    theme_minimal() +
    labs(
      x = &quot;&quot;,
      y = &quot;&quot;,
      title = &quot;Which Words are Important to Which Characters?&quot;
    ) +
    theme(
      axis.text.x = element_blank()
    )</code></pre>
<p><img src="/blog/office-part1_files/figure-html/character%20common%20words-1.png" width="672" /></p>
<p>This looks right – we see that “tuna” and “nard” are important to Andy, which totally makes sense. Some other gems in here are “wuphf” for Ryan, “wimowheh” for Jim, and “awesome” for Kevin.</p>
<p>Next, let’s take a closer look at how Michael’s speech compares to some of the other main characters – Dwight, Jim, and Pam. We’ll also leave Kelly in here because I think she’ll be interesting to compare to Michael.</p>
<pre class="r"><code>main_char_words &lt;-  office_words %&gt;%
  filter(character %in% c(&quot;Michael&quot;, &quot;Dwight&quot;, &quot;Jim&quot;, &quot;Pam&quot;, &quot;Kelly&quot;),
         str_detect(word, &quot;\\d+&quot;, negate = TRUE)) %&gt;%
  count(character, word) %&gt;%
  group_by(character) %&gt;%
  mutate(word_prop = n/sum(n)) %&gt;%
  ungroup() %&gt;%
  select(-n) %&gt;%
  pivot_wider(names_from = character,
              values_from = word_prop)

char_plot &lt;- function(df, char) {
  df %&gt;%
  select(word, Michael, {{char}}) %&gt;%
  mutate(color = log(abs(Michael-{{char}}))) %&gt;%
  ggplot(aes(y = Michael, x = {{char}})) +
    geom_text(aes(label = word, color = color), check_overlap = TRUE, vjust = 1) +
    geom_abline(color = &quot;grey50&quot;, lty = 2) +
    scale_x_log10(labels = scales::percent_format()) +
    scale_y_log10(labels = scales::percent_format()) +
    scale_color_distiller(
      type = &quot;seq&quot;,
      palette = &quot;Purples&quot;,
      direction = 1
    ) +
    theme_minimal() +
    theme(
      legend.position = &quot;none&quot;
    )
}

main_char_words %&gt;%
  char_plot(Dwight)</code></pre>
<p><img src="/blog/office-part1_files/figure-html/dwight%20words-1.png" width="672" /></p>
<p>Ok, so let’s walk through how to read this. For a given word, the y-axis shows how frequently Michael uses that word, and the x-axis shows how frequently Dwight uses that word. The diagonal dotted line represents equal usage – words that appear on or close to the line are words that Michael and Dwight use about as frequently as one another. Words <em>above</em> the line are those that Michael uses more; words <em>below</em> the line are those that Dwight uses more. Words closer to the line will appear lighter in the graph, whereas words farther way will have more color. So, looking at the graph, we can see that Dwight and Michael both say “hey” pretty often and use the word more or less equally. Dwight says “Mose” way more often than Michael does (because it’s farther from the line), whereas Michael says “Scott” more often than Dwight.</p>
<p>Let’s take a look at what these graphs look like for Jim and Pam</p>
<pre class="r"><code>main_char_words %&gt;%
  char_plot(Jim)</code></pre>
<p><img src="/blog/office-part1_files/figure-html/jim%20graph-1.png" width="672" /></p>
<pre class="r"><code>main_char_words %&gt;%
  char_plot(Pam)</code></pre>
<p><img src="/blog/office-part1_files/figure-html/pam%20graph-1.png" width="672" /></p>
<p>Aand let’s throw Kelly in there too because it might be interesting.</p>
<pre class="r"><code>main_char_words %&gt;%
  char_plot(Kelly)</code></pre>
<p><img src="/blog/office-part1_files/figure-html/kelly%20plot-1.png" width="672" /></p>
<p>What we see here is that, at least when compared to Michael, Kelly’s speech is pretty idiosyncratic – there are lots of words (“blah”, “bitch”, “god”) that she uses waaaayy more frequently than Michael does.</p>
<p>And finally (for this section), I would be remiss if I made it through an analysis of how characters from <em>The Office</em> speak without giving a “that’s what she said” tally…</p>
<pre class="r"><code>office %&gt;%
  filter(str_detect(text, &quot;what she said&quot;)) %&gt;%
  count(character) %&gt;%
  ggplot(aes(x = fct_reorder(character, n), y = n)) +
    geom_col(fill = purple) +
    labs(
      x = &quot;&quot;,
      y = &quot;Count&quot;,
      title = &quot;That&#39;s What She Said!&quot;
    ) +
    coord_flip()</code></pre>
<p><img src="/blog/office-part1_files/figure-html/thats%20what%20she%20said-1.png" width="672" /></p>
<p>Not at all a surprise….</p>
</div>
<div id="identity-theft-is-not-a-joke-jim" class="section level3">
<h3>Identity theft is not a joke, Jim!</h3>
<p>Finally, I want to visualize who characters talk to. To do this, I’m going to put together a network plot showing links between characters based on how frequently they interact.</p>
<pre class="r"><code>set.seed(0408)

office_links &lt;- office %&gt;%
  filter(character %in% top_20_chars) %&gt;%
  group_by(episode) %&gt;%
  mutate(to = lead(character)) %&gt;%
  ungroup() %&gt;%
  rename(from = character) %&gt;%
  count(from, to) %&gt;%
  filter(from != to,
         !is.na(to),
         n &gt; 25)

office_verts &lt;- office_links %&gt;%
  group_by(from) %&gt;%
  summarize(size = log(sum(n), base = 2)) %&gt;%
  ungroup()

network_graph &lt;- graph_from_data_frame(office_links, vertices = office_verts)

network_graph %&gt;%
  ggraph(layout = &quot;igraph&quot;, algorithm = &quot;fr&quot;) +
  geom_edge_link(aes(edge_alpha = n^.5), color = purple, edge_width = 1) +
  geom_node_point(aes(size = size, color = size)) +
  geom_node_text(aes(label = name, size = size), repel = TRUE, family = &quot;Garamond&quot;, fontface = &quot;bold&quot;) +
  scale_color_distiller(
      type = &quot;seq&quot;,
      palette = &quot;Purples&quot;,
      direction = 1
    ) +
  labs(
    title = &quot;Who Talks to Whom in The Office?&quot;
  ) +
  theme_void() +
  theme(
    legend.position = &quot;none&quot;,
    plot.title = element_text(hjust = .5)
  )</code></pre>
<p><img src="/blog/office-part1_files/figure-html/network-1.png" width="672" /></p>
<p>The network graph shows links between characters. The size and color of the node (point) associated with a person corresponds to the the total number of interactions they have, with larger and purple-r nodes representing more interactions. The color of the link between characters also corresponds to the number of interactions between two characters, with darker purple links representing more interactions and lighter links representing fewer interactions. Also, characters with more total interactions are sorted toward the center of the network, which is where we see Michael, Jim, Pam, and Dwight. Finally, interactions are only shown if characters have more than 25 total interactions (this prevents the graph from showing a jillion lines).</p>
<p>I’m going to wrap this one up here, but later on I’ll probably play around a bit with doing some statistical modeling – predicting who is speaking, who a character is speaking to, something like that.</p>
</div>
</div>

  </div>
</section>
<section id="tag-pane" class="row meta">
  
  <div class="col-md-12">
    <h6 class="text-right meta">
      
    </h6>
  </div>
  
</section>








<section id="menu-pane" class="row menu text-center">
  
  
  <span><a class="menu-item" href="/blog/vq-mapping/">&lt; prev | </a></span>
  
  
  <span><a class="menu-item" href="/blog">blog</a></span>
  
  
  <span><a class="menu-item" href="/blog/riddler-express-mar-20-20/"> | next &gt;</a></span>
  
  
  <h4 class="text-center"><a class="menu-item" href="/">home</a></h4>
</section>



<footer class="row text-center footer">
  <hr />
  
  <h6 class="text-center copyright">© 2019. Eric Ekholm. <a href="http://creativecommons.org/licenses/by/3.0/">Some Rights Reserved</a>.</h6>
  
  <h6 class="text-center powered">Powered by <a href="https://gohugo.io/">Hugo  v0.61.0</a> &amp; <a href="https://github.com/shenoybr/hugo-goa">Goa</a>.</h6>
  
      
  
</footer>

</div>



<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  

<script type="text/javascript">
hljs.initHighlightingOnLoad();
</script>




<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'XYZ', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<script src="js/main.js"></script>
<script src="js/custom.js"></script>

<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
  });
  MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });

  MathJax.Hub.Config({
  
  TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script>
</body>
</html>


